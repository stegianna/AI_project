{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLNudl-vs8N9"
   },
   "source": [
    "# Real-time People Detection using YOLOv3\n",
    "This work consist in three part:\n",
    "- Connect the webcam to Colab using JavaScript\n",
    "- Predict the people in image streamed by the webcam and get the respective bounding boxes\n",
    "- Put the predicted bounding boxes in the real-time webcam show\n",
    "\n",
    "The written code will not be commented line by line, but we will focus on functionalities instead. For YOLO it's been used the PyTorch implementation by ultralitycs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KizC9YRXw5mX"
   },
   "source": [
    "## Setups and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjTUEOX6xAeP"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import html\n",
    "import io\n",
    "import time\n",
    "\n",
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rex6xev5qP-G"
   },
   "source": [
    "## Define JS code for Webcam Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7OYmjeF-edKE"
   },
   "outputs": [],
   "source": [
    "def start_input():\n",
    "  js = Javascript('''\n",
    "    var video;\n",
    "    var div = null;\n",
    "    var stream;\n",
    "    var captureCanvas;\n",
    "    var imgElement;\n",
    "    var labelElement;\n",
    "    \n",
    "    var pendingResolve = null;\n",
    "    var shutdown = false;\n",
    "    \n",
    "    function removeDom() {\n",
    "       stream.getVideoTracks()[0].stop();\n",
    "       video.remove();\n",
    "       div.remove();\n",
    "       video = null;\n",
    "       div = null;\n",
    "       stream = null;\n",
    "       imgElement = null;\n",
    "       captureCanvas = null;\n",
    "       labelElement = null;\n",
    "    }\n",
    "    \n",
    "    function onAnimationFrame() {\n",
    "      if (!shutdown) {\n",
    "        window.requestAnimationFrame(onAnimationFrame);\n",
    "      }\n",
    "      if (pendingResolve) {\n",
    "        var result = \"\";\n",
    "        if (!shutdown) {\n",
    "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
    "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
    "        }\n",
    "        var lp = pendingResolve;\n",
    "        pendingResolve = null;\n",
    "        lp(result);\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    async function createDom() {\n",
    "      if (div !== null) {\n",
    "        return stream;\n",
    "      }\n",
    "\n",
    "      div = document.createElement('div');\n",
    "      div.style.border = '2px solid black';\n",
    "      div.style.padding = '3px';\n",
    "      div.style.width = '100%';\n",
    "      div.style.maxWidth = '600px';\n",
    "      document.body.appendChild(div);\n",
    "      \n",
    "      const modelOut = document.createElement('div');\n",
    "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
    "      labelElement = document.createElement('span');\n",
    "      labelElement.innerText = 'No data';\n",
    "      labelElement.style.fontWeight = 'bold';\n",
    "      modelOut.appendChild(labelElement);\n",
    "      div.appendChild(modelOut);\n",
    "           \n",
    "      video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      video.width = div.clientWidth - 6;\n",
    "      video.setAttribute('playsinline', '');\n",
    "      video.onclick = () => { shutdown = true; };\n",
    "      stream = await navigator.mediaDevices.getUserMedia(\n",
    "          {video: { facingMode: \"environment\"}});\n",
    "      div.appendChild(video);\n",
    "\n",
    "      imgElement = document.createElement('img');\n",
    "      imgElement.style.position = 'absolute';\n",
    "      imgElement.style.zIndex = 1;\n",
    "      imgElement.onclick = () => { shutdown = true; };\n",
    "      div.appendChild(imgElement);\n",
    "      \n",
    "      const instruction = document.createElement('div');\n",
    "      instruction.innerHTML = \n",
    "          '<span style=\"color: red; font-weight: bold;\">' +\n",
    "          'When finished, click here or on the video to stop this demo</span>';\n",
    "      div.appendChild(instruction);\n",
    "      instruction.onclick = () => { shutdown = true; };\n",
    "      \n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      captureCanvas = document.createElement('canvas');\n",
    "      captureCanvas.width = 512; //video.videoWidth;\n",
    "      captureCanvas.height = 512; //video.videoHeight;\n",
    "      window.requestAnimationFrame(onAnimationFrame);\n",
    "      \n",
    "      return stream;\n",
    "    }\n",
    "    async function takePhoto(label, imgData) {\n",
    "      if (shutdown) {\n",
    "        removeDom();\n",
    "        shutdown = false;\n",
    "        return '';\n",
    "      }\n",
    "\n",
    "      var preCreate = Date.now();\n",
    "      stream = await createDom();\n",
    "      \n",
    "      var preShow = Date.now();\n",
    "      if (label != \"\") {\n",
    "        labelElement.innerHTML = label;\n",
    "      }\n",
    "            \n",
    "      if (imgData != \"\") {\n",
    "        var videoRect = video.getClientRects()[0];\n",
    "        imgElement.style.top = videoRect.top + \"px\";\n",
    "        imgElement.style.left = videoRect.left + \"px\";\n",
    "        imgElement.style.width = videoRect.width + \"px\";\n",
    "        imgElement.style.height = videoRect.height + \"px\";\n",
    "        imgElement.src = imgData;\n",
    "      }\n",
    "      \n",
    "      var preCapture = Date.now();\n",
    "      var result = await new Promise(function(resolve, reject) {\n",
    "        pendingResolve = resolve;\n",
    "      });\n",
    "      shutdown = false;\n",
    "      \n",
    "      return {'create': preShow - preCreate, \n",
    "              'show': preCapture - preShow, \n",
    "              'capture': Date.now() - preCapture,\n",
    "              'img': result};\n",
    "    }\n",
    "    ''')\n",
    "\n",
    "  display(js)\n",
    "  \n",
    "def take_photo(label, img_data):\n",
    "  data = eval_js('takePhoto(\"{}\", \"{}\")'.format(label, img_data))\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0bGVIWmxqjG"
   },
   "source": [
    "In the code section above are defined two functions: `start_input` and `take_photo`. \n",
    "\n",
    "- `start_input` is the function that open the webcam (you need to give to your browser the permission to access to it), then provide the canvas to put everything captured by the webcam and showed it to the Google Colab output.\n",
    "\n",
    "- `take_photo` return JavaScript object containing the image (in bytes) to be processed in YOLOv3. **img_data** (one of the two inputs of this function) is an image, in this specific case a bounding box, that we will overlay on the frame captured by webcam.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIhvoWJxqDNx"
   },
   "source": [
    "## Clone YOLOv3 and Drawing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04K8idMAbWog"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/stegianna/yolov3.git  # clone\n",
    "%cd yolov3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cuf1_2yR9hXD"
   },
   "source": [
    "Now it's possible import the libraries from the YOLOv3 cloned repository and load the pretrained Darknet-53 model.\\\n",
    "After that, the default configurations such as image size, confidence threshold, IOU threshold are initialized. \n",
    "- The pretrained YOLO network weights are obtained from training on 2014 COCO dataset.\n",
    "\n",
    "- `person_class` is a list that contains the object class filtered by the YOLO, in this case the list contains only 0 which represent the class \"person\" (in according with the COCO names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0ZgJiQBskDt"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from sys import platform\n",
    "\n",
    "from models import * \n",
    "from utils.datasets import *\n",
    "from utils.utils import *\n",
    "\n",
    "# Defaul configurations\n",
    "cfg = 'cfg/yolov3-spp.cfg'\n",
    "names = 'data/coco.names'\n",
    "weights = 'weights/yolov3-spp-ultralytics.pt'\n",
    "img_size = 416\n",
    "conf_thresh = 0.3\n",
    "iou_thresh = 0.6\n",
    "person_class = [0]           # 0 correspond to class \"person\"\n",
    "agnostic_nms = False         # by default\n",
    "\n",
    "\n",
    "# Initialize\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Initialize model\n",
    "model = Darknet(cfg, img_size)\n",
    "\n",
    "# Load weights\n",
    "attempt_download(weights)\n",
    "if weights.endswith('.pt'):  # pytorch format\n",
    "    model.load_state_dict(torch.load(weights, map_location=device)['model'])\n",
    "else:  # darknet format\n",
    "    load_darknet_weights(model, weights)\n",
    "\n",
    "model.to(device).eval();\n",
    "\n",
    "# Get names and colors\n",
    "names = load_classes(names)\n",
    "colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n",
    "\n",
    "\n",
    "def js_reply_to_image(js_reply):\n",
    "    \"\"\"\n",
    "    input: \n",
    "          js_reply: JavaScript object, contain image from webcam\n",
    "\n",
    "    output: \n",
    "          image_array: image array RGB size 512 x 512 from webcam\n",
    "    \"\"\"\n",
    "    jpeg_bytes = base64.b64decode(js_reply['img'].split(',')[1])\n",
    "    image_PIL = Image.open(io.BytesIO(jpeg_bytes))\n",
    "    image_array = np.array(image_PIL)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_drawing_array(image_array): \n",
    "    \"\"\"\n",
    "    input: \n",
    "          image_array: image array RGB size 512 x 512 from webcam\n",
    "\n",
    "    output: \n",
    "          drawing_array: image RGBA size 512 x 512 only contain bounding box and text, \n",
    "                              channel A value = 255 if the pixel contains drawing properties (lines, text) \n",
    "                              else channel A value = 0\n",
    "    \"\"\"\n",
    "    drawing_array = np.zeros([512,512,4], dtype=np.uint8)\n",
    "    img = letterbox(image_array, new_shape=img_size)[0]\n",
    "\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = np.ascontiguousarray(img)\n",
    "\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0  # (0 - 255) to (0.0 - 1.0)\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    pred = model(img)[0]\n",
    "    # Apply NMS\n",
    "    pred = non_max_suppression(pred, conf_thresh, iou_thresh, classes=person_class, agnostic=agnostic_nms)\n",
    "    # Process detections\n",
    "    det = pred[0]\n",
    "    if det is not None and len(det):\n",
    "        det[:, :4] = scale_coords(img.shape[2:], det[:, :4], image_array.shape).round()\n",
    "\n",
    "        # Write results\n",
    "        for *xyxy, conf, cls in det:\n",
    "            label = '%s %.2f' % (names[int(cls)], conf)\n",
    "            plot_one_box(xyxy, drawing_array, label=label, color=colors[int(cls)])\n",
    "\n",
    "    drawing_array[:,:,3] = (drawing_array.max(axis = 2) > 0 ).astype(int) * 255\n",
    "\n",
    "    return drawing_array\n",
    "\n",
    "def drawing_array_to_bytes(drawing_array):\n",
    "    \"\"\"\n",
    "    input: \n",
    "          drawing_array: image RGBA size 512 x 512 \n",
    "                              contain bounding box and text from yolo prediction, \n",
    "                              channel A value = 255 if the pixel contains drawing properties (lines, text) \n",
    "                              else channel A value = 0\n",
    "\n",
    "    output: \n",
    "          drawing_bytes: string, encoded from drawing_array\n",
    "    \"\"\"\n",
    "\n",
    "    drawing_PIL = Image.fromarray(drawing_array, 'RGBA')\n",
    "    iobuf = io.BytesIO()\n",
    "    drawing_PIL.save(iobuf, format='png')\n",
    "    drawing_bytes = 'data:image/png;base64,{}'.format((str(base64.b64encode(iobuf.getvalue()), 'utf-8')))\n",
    "    return drawing_bytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZLfEDx_10EV"
   },
   "source": [
    "- `js_reply_to_image` function decodes the image captured from a bytes format and then convert it into an array.\n",
    "\n",
    "- `get_drawing_array` produce an image of the bounding box and label provided by inference execution on the captured frame. The bounding box image will be drawn into an empty canvas in RGBA format (.png), so we can get an image without background.\n",
    "\n",
    "- `drawing_array_to_bytes` transform the input image returned by `get_drawing_array` in Bytes, so now it's in the right format to be passed as argument in `take_photo`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIlKEQ3ruDCw"
   },
   "source": [
    "## Functions execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZi6NXSDyAY6"
   },
   "outputs": [],
   "source": [
    "start_input()\n",
    "label_html = 'Capturing...'\n",
    "img_data = ''\n",
    "count = 0 \n",
    "while True:\n",
    "    js_reply = take_photo(label_html, img_data)\n",
    "    if not js_reply:\n",
    "        break\n",
    "\n",
    "    image = js_reply_to_image(js_reply)\n",
    "    drawing_array = get_drawing_array(image) \n",
    "    drawing_bytes = drawing_array_to_bytes(drawing_array)\n",
    "    img_data = drawing_bytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPsb0Gfn9hAX"
   },
   "source": [
    "`img_data` at the start is an empty string then, in each iteration, it will be replaced by `drawing_bytes`.\n",
    "\n",
    "----\n",
    "\n",
    "First attempt might fail to load image\n",
    "\n",
    "Just double click the red text, and re-run the last box\n",
    "\n",
    "To stop the webcam capture, click red text or the picture"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PeopleDetection_YOLOv3_streamingWebcam.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/vindruid/yolov3-in-colab/blob/master/yolov3_streaming_webcam.ipynb",
     "timestamp": 1605447690695
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
