{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAQLiZTwQHCG"
   },
   "source": [
    "## Clone YOLOv3\n",
    "Clone GitHub repository containing YOLOv3 Pytorch implementation by ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PtfNmjCNmNY"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/stegianna/yolov3.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pb7jMYWnQkJr"
   },
   "source": [
    "## Imports and Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHVK3uVPQolQ"
   },
   "outputs": [],
   "source": [
    "%cd yolov3\n",
    "import time\n",
    "import glob\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "from sys import platform\n",
    "\n",
    "from models import *\n",
    "from utils.datasets import *\n",
    "from utils.utils import *\n",
    "\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WTahs_ngxRE"
   },
   "source": [
    "## Prepare YOLOv3 and Define Functions\n",
    "The default configurations such as image size, confidence threshold, IOU threshold are initialized.\n",
    "\n",
    "`process_video` capture each video frame, process it and write it in a new video file. The function returns the path where the video processed (with bounding boxes) is located.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kojkXHYAL1Kf"
   },
   "outputs": [],
   "source": [
    "# Default configurations\n",
    "cfg = 'cfg/yolov3-spp.cfg'\n",
    "names = 'data/coco.names'\n",
    "weights = 'weights/yolov3-spp-ultralytics.pt'\n",
    "img_size = 416\n",
    "conf_thresh = 0.3\n",
    "iou_thresh = 0.6\n",
    "person_class = [0]           # 0 correspond to class \"person\"\n",
    "agnostic_nms = False         # by default\n",
    "\n",
    "# Initialize\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Initialize model\n",
    "model = Darknet(cfg, img_size)\n",
    "\n",
    "# Load weights\n",
    "attempt_download(weights)\n",
    "if weights.endswith('.pt'):  # pytorch format\n",
    "    model.load_state_dict(torch.load(weights, map_location=device)['model'])\n",
    "else:  # darknet format\n",
    "    load_darknet_weights(model, weights)\n",
    "\n",
    "model.to(device).eval();\n",
    "\n",
    "# Get names and colors\n",
    "names = load_classes(names)\n",
    "colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n",
    "\n",
    "%cd .. \n",
    "\n",
    "def process_video(path_video, output_dir = 'output'): \n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    cap  = cv2.VideoCapture(path_video)\n",
    "    _, img0 = cap.read()\n",
    "\n",
    "    save_path = os.path.join(output_dir, os.path.split(path_video)[-1]) \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'MP4V'), fps, (w, h))\n",
    "\n",
    "    while img0 is not None: \n",
    "\n",
    "        # Padded resize\n",
    "        img = letterbox(img0, new_shape=img_size)[0]\n",
    "\n",
    "        # Convert\n",
    "        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3xHxW\n",
    "        img = np.ascontiguousarray(img)\n",
    "\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        pred = model(img)[0]\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, conf_thresh, iou_thresh, classes=person_class, agnostic=agnostic_nms)\n",
    "\n",
    "        # Process detections\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            im0 = img0 ##### Ganti im0s menjadi img0\n",
    "\n",
    "            if det is not None and len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "                # Write results\n",
    "                for *xyxy, conf, cls in det:\n",
    "                    label = '%s %.2f' % (names[int(cls)], conf)\n",
    "                    plot_one_box(xyxy, im0, label=label, color=colors[int(cls)])\n",
    "\n",
    "        vid_writer.write(im0)\n",
    "        _, img0 = cap.read()\n",
    "\n",
    "    vid_writer.release()\n",
    "\n",
    "    return save_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5SbLvzLU3i_"
   },
   "source": [
    "## Git clone to get video\n",
    "The video is contained in `input_video` folder of my GitHub repository.\\\n",
    "It has been cutted, so the new version has a duration of 20s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LEWy4FDUtXp"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/stegianna/AI_project.git\n",
    "mkdir -p input_video\n",
    "mkdir -p output_compressed\n",
    "ffmpeg -ss 00:00:0.0 -i AI_project/input_video/pedestrian.mp4 -c copy -t 00:00:20.0 input_video/pedestrian.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NekDq0GwhmE4"
   },
   "source": [
    "## Process Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSytfayw0vyM"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path_video = os.path.join(\"input_video\",\"pedestrian.mp4\")\n",
    "save_path = process_video(path_video)\n",
    "\n",
    "# Show video\n",
    "mp4 = open(path_video,'rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=700 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6_5yJAZeqlb"
   },
   "source": [
    "The video processed, before been shown, must to be compressed with H.264 encoding. This in necessary, differently to the original video, because cv2 library has decode it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "osBzRGoxMAE9"
   },
   "outputs": [],
   "source": [
    "# compress video\n",
    "compressed_path = os.path.join(\"output_compressed\", os.path.split(save_path)[-1])\n",
    "os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
    "\n",
    "# Show video\n",
    "mp4 = open(compressed_path,'rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=700 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PedestrianDetection_YOLOv3.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/vindruid/yolov3-in-colab/blob/master/yolov3_video.ipynb",
     "timestamp": 1605634002530
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
